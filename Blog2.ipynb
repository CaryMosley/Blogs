{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lxml\n",
    "import seaborn as sns\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ecstasydata.org/index.php?sort=DatePublishedU+desc&start=0&search_field=-&m1=-1&m2=-1&datefield=tested&max=200\"\n",
    "page = get(url)\n",
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "rows = soup.findAll('tr')\n",
    "\n",
    "rows[4]\n",
    "type(rows[4])\n",
    "name = []\n",
    "substance = []\n",
    "amounts = []\n",
    "soldas = []\n",
    "date_pub = []\n",
    "date_tested = []\n",
    "locations = []\n",
    "sample_size = []\n",
    "i = 0\n",
    "for row in rows:\n",
    "    j = 1\n",
    "    if i > 3:\n",
    "        i=4\n",
    "    else:\n",
    "        for element in row.find_all('a'):\n",
    "            if j == 2:\n",
    "                temp = (str(element))\n",
    "                name.append(temp.split('>')[1].split('<')[0])\n",
    "                break\n",
    "            else:\n",
    "                j= j + 1\n",
    "        i = 1\n",
    "        k = 1\n",
    "        for element in row.find_all('td'):\n",
    "            if k == 2:\n",
    "                try: \n",
    "                    temp2 = str(element.find_all('p'))\n",
    "                    soldas.append(temp2.split('Sold as: ')[1].split('</')[0])\n",
    "                except:\n",
    "                    soldas.append('NA')\n",
    "       \n",
    "            elif k == 3:\n",
    "                try:\n",
    "                    temp3 = str(element.find(class_= 'Substance'))\n",
    "                    substance.append(temp3.split('<li>')[1].split('</li')[0])\n",
    "                except:\n",
    "                    substance.append('NA')\n",
    "            elif k == 4:\n",
    "                try:\n",
    "                    temp4 = str(row.find(class_= 'Amounts'))\n",
    "                    amounts.append(temp4.split('<li>')[1].split('\\xa0')[0])\n",
    "                except:\n",
    "                    amounts.append('NA')\n",
    "        \n",
    "            elif k ==5:\n",
    "                try:\n",
    "                    temp5 = str(element)\n",
    "                    date_pub.append(temp5.split('<td>')[1].split('</')[0])\n",
    "                except:\n",
    "                    date_pub.append('NA')\n",
    "       \n",
    "            elif k == 6:\n",
    "                try:\n",
    "                    temp6 = str(element)\n",
    "                    date_tested.append(temp6.split('<td>')[1].split('</')[0])\n",
    "                except:\n",
    "                    date_tested.append('NA')\n",
    "        \n",
    "            elif k == 7:\n",
    "                try:\n",
    "                    temp7 = str(element)\n",
    "                    locations.append(temp7.split('<td>')[1].split('</')[0])\n",
    "                except:\n",
    "                    locations.append('NA')\n",
    "       \n",
    "            elif k == 8:\n",
    "                try:\n",
    "                    temp8 = str(element)\n",
    "                    sample_size.append(temp8.split('<td>')[1].split('</')[0])\n",
    "                except:\n",
    "                    sample_size.append('NA')\n",
    "            k = k +1\n",
    "        \n",
    "        i = i +1\n",
    "                \n",
    "        \n",
    "        #titles.append(row.find(class_='a-link-normal').text)\n",
    "        #gross.append(row.find(class_='a-text-right mojo-field-type-money').text)\n",
    "        #years.append(row.find(class_='a-text-left mojo-field-type-year').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =str(rows[4].find(class_= 'Amounts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"Amounts\"> <li>14.2Â mg</li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[4].find_all(class_='Amounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSD\n",
      "2\n",
      "DOC\n",
      "3\n",
      "148\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for element in rows[4].find_all('td'):\n",
    "    if i == 2:\n",
    "        temp2 = str(element.find_all('p'))\n",
    "        soldas.append(temp2.split('Sold as: ')[1].split('</')[0])\n",
    "        print(temp2.split('Sold as: ')[1].split('</')[0])\n",
    "        print('2')\n",
    "    elif i == 3:\n",
    "        temp3 = str(element.find(class_= 'Substance'))\n",
    "        substance.append(temp3.split('<li>')[1].split('</li')[0])\n",
    "        print(temp3.split('<li>')[1].split('</li')[0])\n",
    "        print('3')\n",
    "    elif i == 4:\n",
    "        temp4 = str(row.find(class_= 'Amounts'))\n",
    "        amounts.append(temp4.split('<li>')[1].split('\\xa0')[0])\n",
    "        print(temp4.split('<li>')[1].split('\\xa0')[0])\n",
    "        print('4')\n",
    "    elif i ==5:\n",
    "        temp5 = str(element)\n",
    "        date_pub.append(temp5.split('<td>')[1].split('</')[0])\n",
    "        print('5')\n",
    "    elif i == 6:\n",
    "        temp6 = str(element)\n",
    "        date_tested.append(temp6.split('<td>')[1].split('</')[0])\n",
    "        print('6')\n",
    "    elif i == 7:\n",
    "        temp7 = str(element)\n",
    "        locations.append(temp7.split('<td>')[1].split('</')[0])\n",
    "        print('7')\n",
    "    elif i == 8:\n",
    "        temp8 = str(element)\n",
    "        sample_size.append(temp8.split('<td>')[1].split('</')[0])\n",
    "        print('8')\n",
    "    i = i +1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feb 15, 2020',\n",
       " 'Feb 26, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 29, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 21, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 23, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 15, 2020',\n",
       " 'Feb 15, 2020',\n",
       " 'Feb 15, 2020',\n",
       " 'Feb 26, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 25, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 19, 2020',\n",
       " 'Feb 18, 2020',\n",
       " 'Feb 14, 2020',\n",
       " 'Feb 21, 2020',\n",
       " 'Feb 07, 2020',\n",
       " 'Feb 14, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 05, 2020',\n",
       " 'Feb 04, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Feb 01, 2020',\n",
       " 'Feb 01, 2020',\n",
       " 'Feb 01, 2020',\n",
       " 'Feb 01, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Dec 16, 2019',\n",
       " 'Dec 16, 2019',\n",
       " 'Dec 16, 2019',\n",
       " 'Dec 16, 2019',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 31, 2020',\n",
       " 'Jan 29, 2020',\n",
       " 'Jan 25, 2020',\n",
       " 'Jan 29, 2020',\n",
       " 'Jan 28, 2020',\n",
       " 'Jan 28, 2020',\n",
       " 'Jan 28, 2020',\n",
       " 'Jan 25, 2020',\n",
       " 'Jan 25, 2020',\n",
       " 'Jan 25, 2020',\n",
       " 'Jan 25, 2020',\n",
       " 'Jan 25, 2020',\n",
       " 'Jan 24, 2020',\n",
       " 'Jan 24, 2020',\n",
       " 'Jan 17, 2020',\n",
       " 'Jan 24, 2020',\n",
       " 'Jan 24, 2020',\n",
       " 'Jan 24, 2020',\n",
       " 'Jan 21, 2020',\n",
       " 'Jan 17, 2020',\n",
       " 'Jan 17, 2020',\n",
       " 'Jan 15, 2020',\n",
       " 'Jan 15, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 08, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 14, 2020',\n",
       " 'Jan 07, 2020',\n",
       " 'Jan 07, 2020',\n",
       " 'Jan 07, 2020',\n",
       " 'Jan 07, 2020',\n",
       " 'Jan 07, 2020',\n",
       " 'Dec 31, 2019',\n",
       " 'Dec 31, 2019',\n",
       " 'Dec 31, 2019',\n",
       " 'Dec 31, 2019']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0&amp;nbspmm x 4.4&amp;nbspmm']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
